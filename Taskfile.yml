version: '3'

# Taskfile for mcp-web project (uv-based workflow)
# Install task: https://taskfile.dev/installation/
# Install uv: https://docs.astral.sh/uv/
# Usage: task <command>

vars:
  UV: uv
  SRC_DIR: src
  TEST_DIR: tests
  COVERAGE_MIN: 90
  PARALLEL_WORKERS: auto

env:
  PYTHONPATH: "{{.ROOT_DIR}}/{{.SRC_DIR}}"

tasks:
  default:
    desc: Show available tasks
    cmds:
      - task --list

  # Installation tasks
  install:
    desc: Install package and all dependencies using uv
    cmds:
      - "{{.UV}} sync --all-extras"
      - task: install:playwright

  install:playwright:
    desc: Install Playwright browsers
    cmds:
      - "{{.UV}} run playwright install chromium"

  install:pre-commit:
    desc: Install pre-commit hooks
    cmds:
      - "{{.UV}} run pre-commit install"

  # Testing tasks
  test:
    desc: Run all tests (except live tests) - parallel by default
    cmds:
      - "{{.UV}} run pytest -n {{.PARALLEL_WORKERS}} -m 'not live and not benchmark' -v"

  test:fast:
    desc: Run fast tests only (exclude slow, live, benchmark)
    cmds:
      - "{{.UV}} run pytest -n {{.PARALLEL_WORKERS}} -m 'not slow and not live and not benchmark' -v"

  test:unit:
    desc: Run unit tests only
    cmds:
      - "{{.UV}} run pytest -m unit -v"

  test:unit:parallel:
    desc: Run unit tests in parallel using pytest-xdist
    cmds:
      - "{{.UV}} run pytest -n {{.PARALLEL_WORKERS}} -m unit -v"

  test:security:
    desc: Run security tests
    cmds:
      - "{{.UV}} run pytest -m security -v"

  test:golden:
    desc: Run golden/regression tests
    cmds:
      - "{{.UV}} run pytest -m golden -v"

  test:integration:
    desc: Run integration tests
    cmds:
      - "{{.UV}} run pytest -m integration -v"

  test:integration:parallel:
    desc: Run integration tests in parallel
    cmds:
      - "{{.UV}} run pytest -n {{.PARALLEL_WORKERS}} -m integration -v"

  test:live:
    desc: Run live tests (requires network and API key)
    cmds:
      - "{{.UV}} run pytest -m live -v"

  test:bench:
    desc: Run performance benchmarks (parallel with pytest-xdist)
    cmds:
      - "{{.UV}} run pytest -m benchmark --benchmark-only -v -n {{.PARALLEL_WORKERS}} --dist loadgroup"

  test:bench:single:
    desc: Run performance benchmarks (single process for accurate timing)
    cmds:
      - "{{.UV}} run pytest -m benchmark --benchmark-only -v -o addopts=''"

  test:bench:save:
    desc: Run benchmarks and save results for comparison
    cmds:
      - "{{.UV}} run pytest -m benchmark --benchmark-only --benchmark-autosave -v -o addopts=''"

  test:all:
    desc: Run all tests including live tests (requires API keys)
    cmds:
      - "{{.UV}} run pytest -v"

  test:all:parallel:
    desc: Run all tests in parallel
    cmds:
      - "{{.UV}} run pytest -n {{.PARALLEL_WORKERS}} -v"

  test:manual:
    desc: Manual URL summarization test (URL=url QUERY=query)
    cmds:
      - "{{.UV}} run python -m mcp_web.cli test-summarize {{.URL}} {{if .QUERY}}--query \"{{.QUERY}}\"{{end}} {{if .OUTPUT}}-o {{.OUTPUT}}{{end}} --verbose"

  test:robots:
    desc: Test robots.txt handling (URL=url)
    cmds:
      - "{{.UV}} run python -m mcp_web.cli test-robots {{.URL}} {{if .IGNORE}}--ignore{{end}}"

  test:fast:
    desc: Run fast tests only (unit + security) - parallel by default, no LLM required
    cmds:
      - "{{.UV}} run pytest -n {{.PARALLEL_WORKERS}} -m '(unit or security) and not benchmark' -v"

  test:fast:parallel:
    desc: Run fast tests in parallel
    cmds:
      - "{{.UV}} run pytest -n {{.PARALLEL_WORKERS}} -m 'unit or security or golden' -v"

  test:parallel:
    desc: Run tests in parallel (default all except live)
    cmds:
      - "{{.UV}} run pytest -n {{.PARALLEL_WORKERS}} -m 'not live' -v"

  test:coverage:
    desc: Run tests with coverage report
    cmds:
      - "{{.UV}} run pytest --cov={{.SRC_DIR}}/mcp_web --cov-report=term-missing --cov-report=html"
      - echo "Coverage report generated in htmlcov/index.html"

  test:coverage:parallel:
    desc: Run tests with coverage in parallel
    cmds:
      - "{{.UV}} run pytest -n {{.PARALLEL_WORKERS}} --cov={{.SRC_DIR}}/mcp_web --cov-report=term-missing --cov-report=html"

  test:coverage:min:
    desc: Run tests with minimum coverage enforcement
    cmds:
      - "{{.UV}} run pytest --cov={{.SRC_DIR}}/mcp_web --cov-report=term-missing --cov-fail-under={{.COVERAGE_MIN}}"

  test:watch:
    desc: Run tests in watch mode (requires pytest-watch)
    cmds:
      - "{{.UV}} run ptw -- -m 'not live' -v"

  # Code quality tasks
  lint:
    desc: Run all linting checks
    deps: [lint:ruff, lint:format, lint:mypy]

  lint:ruff:
    desc: Run ruff linter
    cmds:
      - "{{.UV}} run ruff check {{.SRC_DIR}} {{.TEST_DIR}}"

  lint:format:
    desc: Check code formatting
    cmds:
      - '{{.UV}} run ruff format --check {{.SRC_DIR}} {{.TEST_DIR}}'

  lint:mypy:
    desc: Run type checking
    cmds:
      - "{{.UV}} run mypy {{.SRC_DIR}} --ignore-missing-imports"

  lint:all:
    desc: Run all linting and quality checks
    deps: [lint, docs:lint]

  # Code formatting tasks
  format:
    desc: Auto-format code with ruff
    cmds:
      - "{{.UV}} run ruff format {{.SRC_DIR}} {{.TEST_DIR}}"
      - "{{.UV}} run ruff check --fix {{.SRC_DIR}} {{.TEST_DIR}}"

  # Security tasks
  security:
    desc: Run all security checks
    deps: [security:bandit, security:semgrep, security:safety]

  security:bandit:
    desc: Run Bandit security scanner
    cmds:
      - "{{.UV}} run bandit -r {{.SRC_DIR}} -c .bandit -f screen"

  security:semgrep:
    desc: Run Semgrep pattern scanner
    cmds:
      - "{{.UV}} run semgrep --config=.semgrep.yml {{.SRC_DIR}} --error"

  security:safety:
    desc: Check for known vulnerabilities in dependencies
    cmds:
      - "{{.UV}} run safety check --json"

  # Quality analysis
  analyze:
    desc: Run complete static analysis
    deps: [lint, security]

  analyze:complexity:
    desc: Analyze code complexity (requires radon)
    cmds:
      - "{{.UV}} run radon cc {{.SRC_DIR}} -a -nb"

  analyze:maintainability:
    desc: Analyze maintainability index (requires radon)
    cmds:
      - "{{.UV}} run radon mi {{.SRC_DIR}} -nb"

  # Documentation tasks
  docs:build:
    desc: Build documentation (if using Sphinx/MkDocs)
    cmds:
      - echo "Documentation build not yet configured"

  docs:serve:
    desc: Serve documentation locally
    cmds:
      - echo "Documentation server not yet configured"

  docs:lint:
    desc: Lint all documentation (markdown + prose + file naming)
    cmds:
      - task: docs:lint:markdown
      - task: docs:lint:prose
      - task: docs:lint:names
      - task: docs:validate:agents

  docs:lint:markdown:
    desc: Lint markdown structure
    cmds:
      - npx markdownlint-cli2 "**/*.md" "#node_modules" "#.venv"

  docs:lint:prose:
    desc: Lint prose quality with Vale
    cmds:
      - vale --config=.vale.ini docs/ README.md

  docs:lint:names:
    desc: Validate file naming conventions with ls-lint
    cmds:
      - npx @ls-lint/ls-lint

  docs:validate:agents:
    desc: Validate AGENTS.md structure and links
    cmds:
      - |
        echo "Validating docs/AGENTS.md..."
        # Check file exists
        if [ ! -f docs/AGENTS.md ]; then
          echo "ERROR: docs/AGENTS.md not found"
          exit 1
        fi
        # Check required sections exist
        required_sections=("Overview" "Agent Entry Template" "Agents in This Repository" "Adding or Updating Agents")
        for section in "${required_sections[@]}"; do
          if ! grep -q "## $section" docs/AGENTS.md; then
            echo "ERROR: Missing required section: $section"
            exit 1
          fi
        done
        # Validate internal links (check files exist)
        # Skip code blocks by removing content between ``` markers
        echo "Checking internal links..."
        broken_links=0
        # Remove code blocks from file before extracting links
        content=$(awk '/^```/{f=!f;next}!f' docs/AGENTS.md)
        while IFS= read -r link; do
          # Skip external links (http/https)
          if [[ "$link" =~ ^https?:// ]]; then
            continue
          fi
          # Skip anchor-only links
          if [[ "$link" =~ ^# ]]; then
            continue
          fi
          # Skip placeholder/template links
          if [[ "$link" =~ ^(relative/path/to|path/to) ]]; then
            continue
          fi
          # Remove anchor from link if present
          file_path="${link%%#*}"
          # Check relative to docs/ directory
          if [ ! -f "docs/$file_path" ] && [ ! -f "$file_path" ]; then
            echo "  ✗ Broken link: $link"
            broken_links=$((broken_links + 1))
          fi
        done < <(echo "$content" | grep -oP '\[.*?\]\(\K[^)]+')
        if [ $broken_links -gt 0 ]; then
          echo "ERROR: Found $broken_links broken internal link(s)"
          exit 1
        fi
        echo "✓ AGENTS.md validation passed"

  docs:fix:
    desc: Auto-fix markdown issues
    cmds:
      - npx markdownlint-cli2 --fix "**/*.md" "#node_modules" "#.venv"

  docs:clean:
    desc: Remove double-spaces and LLM artifacts
    cmds:
      - |
        find docs/ README.md -type f -name "*.md" -exec sed -i 's/  \+/ /g' {} \;
        echo "Cleaned double-spaces from documentation"

  # Development tasks
  dev:setup:
    desc: Complete development environment setup
    cmds:
      - task: install
      - task: install:pre-commit
      - echo "Development environment ready!"

  dev:clean:
    desc: Clean build artifacts and caches
    cmds:
      - rm -rf build/ dist/ *.egg-info
      - rm -rf .pytest_cache/ .mypy_cache/ .ruff_cache/
      - rm -rf htmlcov/ .coverage .hypothesis/
      - find . -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true
      - echo "Cleaned build artifacts and caches"

  dev:clean:cache:
    desc: Clean application cache
    cmds:
      - rm -rf ~/.cache/mcp-web
      - echo "Cleaned application cache"

  # Pre-commit tasks
  pre-commit:
    desc: Run pre-commit checks
    deps: [lint, test:fast]

  pre-commit:all:
    desc: Run pre-commit on all files
    cmds:
      - "{{.UV}} run pre-commit run --all-files"

  # CI/CD simulation
  ci:
    desc: Simulate CI pipeline locally
    cmds:
      - echo "=== Running CI Pipeline ==="
      - task: lint
      - task: test:coverage:min
      - task: security
      - echo "=== CI Pipeline Complete ==="

  ci:fast:
    desc: Fast CI check (no coverage, parallel tests)
    cmds:
      - echo "=== Running Fast CI ==="
      - task: lint
      - task: test:fast:parallel
      - task: security:bandit
      - echo "=== Fast CI Complete ==="

  ci:parallel:
    desc: Full CI with parallel testing
    cmds:
      - echo "=== Running Parallel CI ==="
      - task: lint
      - task: test:coverage:parallel
      - task: security
      - echo "=== Parallel CI Complete ==="

  # Benchmarking tasks
  bench:
    desc: Run all benchmarks
    cmds:
      - "{{.UV}} run pytest -m benchmark --benchmark-only --benchmark-autosave"

  bench:compare:
    desc: Compare with previous benchmark
    cmds:
      - "{{.UV}} run pytest -m benchmark --benchmark-only --benchmark-compare"

  bench:profile:
    desc: Profile performance with cProfile
    cmds:
      - "{{.UV}} run python -m cProfile -o profile.stats -m pytest -m benchmark"
      - "{{.UV}} run python -c 'import pstats; p = pstats.Stats(\"profile.stats\"); p.sort_stats(\"cumulative\"); p.print_stats(30)'"

  # Docker tasks (if needed)
  docker:build:
    desc: Build Docker image
    cmds:
      - docker build -t mcp-web:latest .

  docker:test:
    desc: Run tests in Docker
    cmds:
      - docker run --rm mcp-web:latest task test

  # Release tasks
  release:check:
    desc: Check if ready for release
    cmds:
      - task: ci
      - task: test:all
      - echo "✓ Ready for release"

  release:build:
    desc: Build distribution packages
    cmds:
      - "{{.UV}} build"
      - echo "Distribution packages built in dist/"

  release:test-pypi:
    desc: Upload to TestPyPI
    cmds:
      - "{{.UV}} publish --publish-url https://test.pypi.org/legacy/"

  release:pypi:
    desc: Upload to PyPI
    cmds:
      - "{{.UV}} publish"

  # Utility tasks
  shell:
    desc: Start Python shell with package imported
    cmds:
      - "{{.UV}} run python -i -c 'from mcp_web import *; print(\"mcp-web shell ready\")'"

  deps:update:
    desc: Update dependencies
    cmds:
      - "{{.UV}} lock --upgrade"

  deps:tree:
    desc: Show dependency tree
    cmds:
      - "{{.UV}} tree"

  deps:outdated:
    desc: Check for outdated dependencies
    cmds:
      - "{{.UV}} pip list --outdated"

  # Local LLM tasks
  llm:ollama:start:
    desc: Start Ollama server (if installed)
    cmds:
      - ollama serve

  llm:ollama:pull:
    desc: Pull recommended Ollama models
    cmds:
      - ollama pull llama3.2:3b
      - ollama pull mistral:7b
      - ollama pull phi3:mini

  llm:test:local:
    desc: Test with local LLM (requires Ollama running)
    env:
      MCP_WEB_SUMMARIZER_API_BASE: http://localhost:11434/v1
      MCP_WEB_SUMMARIZER_MODEL: llama3.2:3b
      MCP_WEB_SUMMARIZER_API_KEY: ollama
    cmds:
      - "{{.UV}} run pytest -m golden -v"

  # Golden test management
  golden:update:
    desc: Update golden test expectations (use with caution)
    cmds:
      - "{{.UV}} run pytest -m golden --update-golden -v"

  golden:verify:
    desc: Verify golden tests with detailed output
    cmds:
      - "{{.UV}} run pytest -m golden -vv --tb=long"

  # Information tasks
  info:
    desc: Show project information
    cmds:
      - echo "Project{{\":\"}} mcp-web"
      - "{{.UV}} run python --version"
      - "{{.UV}} run pytest --version"
      - "{{.UV}} run ruff --version"
      - echo "Coverage minimum{{\":\"}} {{.COVERAGE_MIN}}%"
      - echo "Parallel workers{{\":\"}} {{.PARALLEL_WORKERS}}"

  info:env:
    desc: Show environment configuration
    cmds:
      - "{{.UV}} run python -c 'from mcp_web.config import MCPWebConfig; import json; print(json.dumps(MCPWebConfig().model_dump(), indent=2))'"
