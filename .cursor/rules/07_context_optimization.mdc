---
alwaysApply: false
description: Apply when dealing with large files, complex operations, or memory-intensive tasks
title: Context Optimization
tags: ['context', 'optimization', 'memory', 'performance']
---

related:
  - "/docs/adr/0001-decision.md"

# Context Optimization Guidelines

## Model Decision Rule Loading

**For Cursor IDE:** This rule uses glob matching as a best-effort approach. When working with large files or complex operations, consider loading additional context rules manually.

**Available context rules to load when needed:**

- **Security Practices**: `/rules/06_security_practices.mdc` - For security-sensitive code, API calls, user input, LLM interactions, and authentication
- **Context Optimization**: `/rules/07_context_optimization.mdc` - For large files, complex operations, or memory-intensive tasks
- **File Operations**: `/rules/08_file_operations.mdc` - For file manipulation, directory operations, and path handling
- **Git Workflows**: `/rules/09_git_workflows.mdc` - For git operations, branching, and version control
- **Session Protocols**: `/rules/10_session_protocols.mdc` - For session management and protocol adherence
- **Error Handling**: `/rules/11_error_handling.mdc` - For robust error handling and recovery
- **Task Orchestration**: `/rules/12_task_orchestration.mdc` - For complex task management and coordination
- **Workflow Routing**: `/rules/13_workflow_routing.mdc` - For workflow selection and routing decisions
- **Automation Scripts**: `/rules/14_automation_scripts.mdc` - For automation and scripting tasks
- **Tool Patterns**: `/rules/15_tool_patterns.mdc` - For tool usage patterns and best practices

## Context Loading Strategy

### Automatic Loading (Glob Matching)

Rules are automatically loaded when editing files matching these patterns:
- `*.py, **/*.py` - Python source files
- `tests/**/*.py, conftest.py` - Test files
- `*.md, docs/**/*.md` - Documentation files

### Manual Loading (Context-Aware)

When working on specific tasks, manually reference relevant rules:

```markdown
# Load these rules if you determine you need them based on their descriptions:

- Security Practices: `/rules/06_security_practices.mdc` - Apply when dealing with security-sensitive code including API calls, user input, LLM interactions, and authentication
- Context Optimization: `/rules/07_context_optimization.mdc` - Apply when dealing with large files, complex operations, or memory-intensive tasks
- File Operations: `/rules/08_file_operations.mdc` - Apply when performing file manipulation, directory operations, or path handling
```

## Memory Management

### Large File Handling

```python
# Use generators for large datasets
def process_large_file(path: str) -> Iterator[str]:
    """Process file line by line (memory efficient)."""
    with open(path) as f:
        for line in f:
            yield process_line(line)

# Stream processing for large data
async def stream_large_dataset(data_source: str) -> AsyncIterator[dict]:
    """Stream large dataset in chunks."""
    async with open(data_source) as f:
        async for line in f:
            yield parse_line(line)
```

### Context Window Optimization

```python
# Batch operations to reduce context
async def batch_process(items: list[str], batch_size: int = 100) -> list[dict]:
    """Process items in batches to manage context."""
    results = []
    for i in range(0, len(items), batch_size):
        batch = items[i:i + batch_size]
        batch_result = await process_batch(batch)
        results.extend(batch_result)
    return results

# Use summaries for large content
def summarize_large_content(content: str, max_length: int = 1000) -> str:
    """Create summary of large content for context."""
    if len(content) <= max_length:
        return content

    # Extract key sections
    summary = content[:max_length//2] + "\n...\n" + content[-max_length//2:]
    return summary
```

## Performance Optimization

### Parallel Processing

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

# CPU-bound parallel processing
def parallel_cpu_task(items: list[str]) -> list[dict]:
    """Process CPU-bound tasks in parallel."""
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(process_item, item) for item in items]
        return [future.result() for future in futures]

# IO-bound parallel processing
async def parallel_io_task(urls: list[str]) -> list[dict]:
    """Process IO-bound tasks in parallel."""
    tasks = [fetch_url(url) for url in urls]
    return await asyncio.gather(*tasks, return_exceptions=True)
```

### Caching Strategy

```python
from functools import lru_cache
import functools

# Function result caching
@lru_cache(maxsize=1000)
def expensive_computation(n: int) -> int:
    """Cache expensive computation results."""
    return complex_calculation(n)

# Async caching with TTL
_cache: dict[str, tuple[any, float]] = {}

async def cached_async_operation(key: str, operation: callable, ttl: int = 3600) -> any:
    """Cache async operation results with TTL."""
    now = time.time()

    if key in _cache:
        result, timestamp = _cache[key]
        if now - timestamp < ttl:
            return result

    result = await operation()
    _cache[key] = (result, now)
    return result
```

## Context-Aware Operations

### Smart File Reading

```python
def smart_read_file(file_path: str, max_size: int = 10000) -> str:
    """Read file with size awareness."""
    file_size = Path(file_path).stat().st_size

    if file_size > max_size:
        # Read first and last parts for large files
        with open(file_path, 'r') as f:
            start = f.read(max_size // 2)
            f.seek(-max_size // 2, 2)
            end = f.read()
        return start + "\n...\n" + end
    else:
        return Path(file_path).read_text()
```

### Intelligent Batching

```python
def intelligent_batch(items: list[str], max_batch_size: int = 100) -> list[list[str]]:
    """Create intelligent batches based on item complexity."""
    batches = []
    current_batch = []
    current_size = 0

    for item in items:
        item_size = len(item)  # Simple size estimation
        if current_size + item_size > max_batch_size and current_batch:
            batches.append(current_batch)
            current_batch = [item]
            current_size = item_size
        else:
            current_batch.append(item)
            current_size += item_size

    if current_batch:
        batches.append(current_batch)

    return batches
```

## Rule Loading Best Practices

### Context-Aware Rule Selection

1. **Analyze the task** - Determine what type of work you're doing
2. **Check file patterns** - See if glob matching applies
3. **Manual loading** - Reference specific rules when needed
4. **Context switching** - Load different rules for different phases

### Example Usage

```markdown
# Working on authentication system
Load: Security Practices rule for input validation and API key handling

# Processing large dataset
Load: Context Optimization rule for memory management and batching

# File manipulation tasks
Load: File Operations rule for safe path handling and file operations
```

## Rule Metadata

**File:** `07_context_optimization.yaml`
**Trigger:** model_decision (Windsurf) / globs (Cursor)
**Estimated Tokens:** ~1,800
**Last Updated:** 2025-10-22
**Status:** Active

**Topics Covered:**
- Context optimization
- Memory management
- Performance optimization
- Rule loading strategies

**Workflow References:**
- /implement - Context-aware implementation
- /validate - Performance validation

**Dependencies:**
- Source: 07_context_optimization.md
